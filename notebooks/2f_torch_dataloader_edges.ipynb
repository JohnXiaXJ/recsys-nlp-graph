{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from src.utils.logger import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'electronics'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/{}_edges_train_samp.csv'.format(dataset))\n",
    "val = pd.read_csv('../data/{}_edges_val_samp.csv'.format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_set = set(df['product1'].tolist() + df['product2'].tolist() + val['product1'].tolist() + val['product2'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapping_dicts(product_set):\n",
    "    word2id = dict()\n",
    "    id2word = dict()\n",
    "\n",
    "    wid = 0\n",
    "    for w in product_set:\n",
    "        word2id[w] = wid\n",
    "        id2word[wid] = w\n",
    "        wid += 1\n",
    "\n",
    "    return word2id, id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-13 10:07:55,570 - Len of word2id: 128,802\n"
     ]
    }
   ],
   "source": [
    "word2id, id2word = get_mapping_dicts(product_set)\n",
    "logger.info('Len of word2id: {:,}'.format(len(word2id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_id(x):\n",
    "    return word2id.get(x, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id_func = np.vectorize(get_product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product1_id'] = word2id_func(df['product1'])\n",
    "df['product2_id'] = word2id_func(df['product2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_df = df[['product1_id', 'product2_id', 'weight']].copy().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.85400e+03, 4.11320e+04, 1.00000e+00],\n",
       "       [1.57460e+04, 5.25720e+04, 1.00000e+00],\n",
       "       [1.21606e+05, 6.80420e+04, 2.00000e+00],\n",
       "       ...,\n",
       "       [8.40210e+04, 1.14213e+05, 1.00000e+00],\n",
       "       [1.95740e+04, 1.07128e+05, 1.00000e+00],\n",
       "       [1.27100e+04, 1.16752e+05, 5.00000e-01]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_freq(pair_df):\n",
    "    product_counts = list(itertools.chain.from_iterable(pair_df))\n",
    "    word_freq = Counter(product_counts)\n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = get_word_freq(pair_df[:, :2].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEGATIVE_SAMPLE_TABLE_SIZE = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negative_sample_table(word_freq, power=0.75) -> np.array:\n",
    "    \"\"\"\n",
    "    Returns a table (size = NEGATIVE_SAMPLE_TABLE_SIZE) of negative samples which can be selected via indexing.\n",
    "\n",
    "    Args:\n",
    "        power:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    # Convert to array\n",
    "    word_freq = np.array(list(word_freq.items()), dtype=np.float64)\n",
    "\n",
    "    # Adjust by power\n",
    "    word_freq[:, 1] = word_freq[:, 1] ** power\n",
    "\n",
    "    # Get probabilities\n",
    "    word_freq_sum = word_freq[:, 1].sum()\n",
    "    word_freq[:, 1] = word_freq[:, 1] / word_freq_sum\n",
    "\n",
    "    # Multiply probabilities by sample table size\n",
    "    word_freq[:, 1] = np.round(word_freq[:, 1] * NEGATIVE_SAMPLE_TABLE_SIZE)\n",
    "\n",
    "    # Convert to int\n",
    "    word_freq = word_freq.astype(int).tolist()\n",
    "\n",
    "    # Create sample table\n",
    "    sample_table = [[tup[0]] * tup[1] for tup in word_freq]\n",
    "    sample_table = np.array(list(itertools.chain.from_iterable(sample_table)))\n",
    "    np.random.shuffle(sample_table)\n",
    "\n",
    "    return sample_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_table = get_negative_sample_table(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_idx = 0\n",
    "def get_negative_samples(context, sample_size=5) -> np.array:\n",
    "    \"\"\"\n",
    "    Returns a list of negative samples, where len = sample_size.\n",
    "\n",
    "    Args:\n",
    "        sample_size:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    negative_idx = 0\n",
    "    while True:\n",
    "        # Get a batch from the shuffled table\n",
    "        neg_sample = neg_table[negative_idx:negative_idx + sample_size]\n",
    "\n",
    "        # Update negative index\n",
    "        negative_idx = (negative_idx + sample_size) % len(neg_table)\n",
    "\n",
    "        # Check if batch insufficient\n",
    "        if len(neg_sample) != sample_size:\n",
    "            neg_sample = np.concatenate((neg_sample, neg_table[:negative_idx]))\n",
    "\n",
    "        # Check if context in negative sample\n",
    "        if not context in neg_sample:\n",
    "            return neg_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_negative_samples(121656)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml.data_loader_edges import Edges, EdgesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-13 10:10:20,678 - Edges loaded (length = 9,999)\n",
      "2019-12-13 10:10:20,756 - Validation set loaded: (100000, 3)\n",
      "2019-12-13 10:10:20,838 - No. of unique tokens: 128802\n",
      "2019-12-13 10:10:22,034 - Model saved to model/word2id_edge\n",
      "2019-12-13 10:10:23,217 - Model saved to model/id2word_edge\n",
      "2019-12-13 10:10:23,217 - Word2Id and Id2Word created and saved\n",
      "2019-12-13 10:10:23,237 - Edges prepared\n"
     ]
    }
   ],
   "source": [
    "dataset = 'electronics'\n",
    "edges = Edges(edge_path='../data/{}_edges_train_samp.csv'.format(dataset),\n",
    "              val_path='../data/{}_edges_val_samp.csv'.format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9996217"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges.neg_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 57910, 123297,  72649, 123626,  19100])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.get_negative_samples(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = edges.edges[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45651, 96516,     2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96516"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EdgesDataset(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=5, collate_fn=dataset.collate_continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-13 10:10:28,521 - i: 0, batches: (tensor([  7854,   7854,   7854,   7854,   7854,   7854,  15746,  15746,  15746,\n",
      "         15746,  15746,  15746, 121606, 121606, 121606, 121606, 121606, 121606,\n",
      "         98156,  98156,  98156,  98156,  98156,  98156,  45651,  45651,  45651,\n",
      "         45651,  45651,  45651]), tensor([ 41132,  76249,  79665,  44770,  44310,  49603,  52572, 117187,  31609,\n",
      "         71384,  12211,   4100,  68042,  67788,  86698,  18276,   7869,  47684,\n",
      "        112014, 124112,  13020,  71960,  70662,  25855,  96516,  92665,  54844,\n",
      "         22578, 112309,  95797]), tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0.]))\n",
      "2019-12-13 10:10:28,526 - i: 1, batches: (tensor([ 87057,  87057,  87057,  87057,  87057,  87057,  48254,  48254,  48254,\n",
      "         48254,  48254,  48254, 122944, 122944, 122944, 122944, 122944, 122944,\n",
      "         66545,  66545,  66545,  66545,  66545,  66545, 121354, 121354, 121354,\n",
      "        121354, 121354, 121354]), tensor([ 52565,  21883, 117372,  88705,  79706,  64571,  18103, 115019, 113806,\n",
      "         94067,  17026,    231,  27205,  83878,  21937,   1204,  16916,  72694,\n",
      "        114974,  93438,   9216,  69733,   6456,  60495, 112181,  25521,  76890,\n",
      "        106464, 115639,  80131]), tensor([0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000]))\n",
      "2019-12-13 10:10:28,530 - i: 2, batches: (tensor([  7864,   7864,   7864,   7864,   7864,   7864,  90267,  90267,  90267,\n",
      "         90267,  90267,  90267,  49073,  49073,  49073,  49073,  49073,  49073,\n",
      "         63269,  63269,  63269,  63269,  63269,  63269, 117134, 117134, 117134,\n",
      "        117134, 117134, 117134]), tensor([ 22476,  31595,  30328,   2475, 101121,  74828,  40396,  28620,  28083,\n",
      "        122993,  67364, 113787,  24801, 118175,  71370,  36846,  75995, 100730,\n",
      "         49286, 118456,  21261,   2847,  89954,   1370, 110932,  26170, 121502,\n",
      "         34452,   9814,   6366]), tensor([1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]))\n"
     ]
    }
   ],
   "source": [
    "for i, batches in enumerate(dataloader):\n",
    "    if i > 2:\n",
    "        break\n",
    "    logger.info('i: {}, batches: {}'.format(i, batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    7706\n",
       "2.0    1299\n",
       "0.5     504\n",
       "2.2     199\n",
       "3.2     122\n",
       "1.5     113\n",
       "2.5      18\n",
       "4.4      12\n",
       "1.2      11\n",
       "2.7       5\n",
       "3.7       4\n",
       "3.0       4\n",
       "1.7       1\n",
       "4.2       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(edges.edges[:, 2]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([287628, 287628, 287628, 287628, 287628, 287628, 394067, 394067, 394067,\n",
       "        394067, 394067, 394067,  97662,  97662,  97662,  97662,  97662,  97662,\n",
       "        306502, 306502, 306502, 306502, 306502, 306502, 385155, 385155, 385155,\n",
       "        385155, 385155, 385155])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
