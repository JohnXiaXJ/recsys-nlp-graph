{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.ml.data_loader_with_meta import Sequences, SequencesDataset\n",
    "from src.ml.skipgram import SkipGram as SkipGramBase\n",
    "from src.ml.skipgram_with_meta_weighted import SkipGram\n",
    "from src.utils.logger import logger\n",
    "from src.utils.io_utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 1\n",
    "shuffle = False\n",
    "num_workers = 4\n",
    "emb_dim = 8\n",
    "epochs = 1\n",
    "initial_lr=0.025\n",
    "MODEL_PATH = '../model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'electronics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-09 16:42:39,860 - Sequences loaded (length = 5,000)\n",
      "2019-12-09 16:42:39,936 - Validation set loaded: (100000, 3)\n",
      "2019-12-09 16:42:39,944 - Word frequency calculated\n",
      "2019-12-09 16:42:39,981 - Adding val products to word2id, original size: 28695\n",
      "2019-12-09 16:42:40,049 - Added val products to word2id, updated size: 133050\n",
      "2019-12-09 16:42:40,053 - No. of unique tokens: 133050\n",
      "2019-12-09 16:42:41,312 - Model saved to model/word2id\n",
      "2019-12-09 16:42:42,532 - Model saved to model/id2word\n",
      "2019-12-09 16:42:42,533 - Word2Id and Id2Word created and saved\n",
      "2019-12-09 16:42:46,268 - No. of rows in meta before filter by word2id: 498196\n",
      "2019-12-09 16:42:46,424 - No. of rows in meta after filter by word2id: 79566\n",
      "2019-12-09 16:42:46,633 - Model saved to model/encoder\n",
      "2019-12-09 16:42:47,923 - Embedding dimensions: OrderedDict([('product', 133050), ('category_lvl_3', 55)])\n",
      "2019-12-09 16:42:48,606 - Model saved to model/meta_dict\n",
      "2019-12-09 16:42:48,693 - Convert sequence and wordfreq to ID\n",
      "2019-12-09 16:42:48,728 - Discard probability calculated\n",
      "2019-12-09 16:42:50,114 - Negative sample table created\n"
     ]
    }
   ],
   "source": [
    "sequences = Sequences('../data/{}_sequences_samp.npy'.format(dataset), \n",
    "                      '../data/{}_edges_val_samp.csv'.format(dataset),\n",
    "                      '../data/{}_meta.csv'.format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_dset = SequencesDataset(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_dload = DataLoader(sequences_dset, batch_size=batchsize, shuffle=shuffle, num_workers=num_workers, collate_fn=sequences_dset.collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133050"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.emb_sizes['product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-09 16:46:29,886 - Model initialized: SkipGram(\n",
      "  (center_embeddings): ModuleList(\n",
      "    (0): Embedding(133050, 8, sparse=True)\n",
      "    (1): Embedding(55, 8, sparse=True)\n",
      "  )\n",
      "  (context_embeddings): ModuleList(\n",
      "    (0): Embedding(133050, 8, sparse=True)\n",
      "    (1): Embedding(55, 8, sparse=True)\n",
      "  )\n",
      "  (emb_weights): Embedding(133050, 2, sparse=True)\n",
      "  (emb_weights_softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "skipgram = SkipGram(sequences.emb_sizes, emb_dim).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-09 16:40:01,724 - Epoch: 0, Seq Count: 0/5000, Loss: 0.4157, Lr: 0.025000\n",
      "2019-12-09 16:40:10,821 - Epoch: 0, Seq Count: 1,000/5000, Loss: 4.0503, Lr: 0.022608\n",
      "2019-12-09 16:40:20,148 - Epoch: 0, Seq Count: 2,000/5000, Loss: 4.1510, Lr: 0.016355\n",
      "2019-12-09 16:40:29,328 - Epoch: 0, Seq Count: 3,000/5000, Loss: 4.1650, Lr: 0.008630\n",
      "2019-12-09 16:40:38,706 - Epoch: 0, Seq Count: 4,000/5000, Loss: 4.1127, Lr: 0.002383\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SparseAdam(skipgram.parameters(), lr=initial_lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(sequences_dload))\n",
    "    \n",
    "    running_loss = 0\n",
    "    for i, batches in enumerate(sequences_dload):\n",
    "\n",
    "        # logger.info('Batch shape: {}, {}, {}'.format(batches[0].shape, batches[1].shape, batches[2].shape))\n",
    "        centers = batches[0].to(device)\n",
    "        contexts = batches[1].to(device)\n",
    "        neg_contexts = batches[2].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = skipgram.forward(centers, contexts, neg_contexts)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        running_loss = running_loss * 0.9 + loss.item() * 0.1\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            logger.info('Epoch: {:,}, Seq Count: {:,}/{}, Loss: {:.4f}, Lr: {:.6f}'.format(epoch, i, len(sequences_dload), running_loss,\n",
    "                                                                                        optimizer.param_groups[0][\n",
    "                                                                                            'lr']))\n",
    "            running_loss = 0\n",
    "\n",
    "    # skipgram.save_embeddings(file_name='{}/skipgram_epoch_{}.npy'.format(MODEL_PATH, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_centers = []\n",
    "for i in range(centers.shape[1]):\n",
    "    logger.info('center i: {}, center: {}'.format(i, centers[:, i]))\n",
    "    emb_centers.append(skipgram.center_embeddings[i](centers[:, i]))\n",
    "emb_center = torch.mean(torch.stack(emb_centers), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences.n_unique_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences.emb_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_weights = nn.Embedding(sequences.n_unique_tokens, len(sequences.emb_sizes))\n",
    "emb_equal_weight = 1 / (len(sequences.emb_sizes) + 1)\n",
    "emb_weights.weight.data.uniform_(emb_equal_weight, emb_equal_weight)\n",
    "\n",
    "emb_weights_softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_weightage = emb_weights(centers[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_weightage[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_weightage_norm = emb_weights_softmax(emb_weightage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_weightage_norm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.stack(emb_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_weighted = embs * emb_weightage_norm.T.unsqueeze(2).expand_as(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(embs_weighted, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3447,  3447,  3447,  3447,  3447, 17085, 17085, 17085, 17085, 17085,\n",
       "        13751, 13751, 13751, 13751, 13751, 13751, 28690, 28690, 28690, 28690,\n",
       "        28690, 28690, 28690, 28691, 28691, 28691, 28691, 28691, 28691, 28691,\n",
       "        28691, 28692, 28692, 28692, 28692, 28692, 28692, 28692, 28692,  9208,\n",
       "         9208,  9208,  9208,  9208,  9208,  9208,  9208, 28693, 28693, 28693,\n",
       "        28693, 28693, 28693, 28693, 11462, 11462, 11462, 11462, 11462, 11462,\n",
       "        28694, 28694, 28694, 28694, 28694])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8368, 0.8811],\n",
       "        [0.8368, 0.8811],\n",
       "        [0.8368, 0.8811],\n",
       "        [0.5910, 0.6241],\n",
       "        [0.5910, 0.6241]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgram.emb_weights(centers[:, 0])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0489, -0.0327, -0.0250,  0.0094, -0.0116, -0.0125,  0.0161,  0.0340],\n",
       "        [-0.0489, -0.0327, -0.0250,  0.0094, -0.0116, -0.0125,  0.0161,  0.0340],\n",
       "        [-0.0489, -0.0327, -0.0250,  0.0094, -0.0116, -0.0125,  0.0161,  0.0340],\n",
       "        [ 0.0306, -0.0034, -0.0086,  0.0134, -0.0040, -0.0083,  0.0137, -0.0009],\n",
       "        [ 0.0306, -0.0034, -0.0086,  0.0134, -0.0040, -0.0083,  0.0137, -0.0009]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgram.get_embedding(centers)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save torch params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(skipgram.state_dict(), '../model/skipgram_sample.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SkipGram(sequences.n_unique_tokens, emb_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('../model/skipgram_sample.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_samp = pd.read_csv('../data/{}_edges_val_samp.csv'.format(dataset), dtype={'product1': 'object', 'product2': 'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-09 16:44:05,420 - Model loaded from: ../model/word2id (Size: 16818322 bytes)\n"
     ]
    }
   ],
   "source": [
    "word2id = load_model('../model/word2id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id_func =  np.vectorize(sequences.get_product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_samp['product1_id'] = word2id_func(val_samp['product1'].values)\n",
    "val_samp['product2_id'] = word2id_func(val_samp['product2'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_and_meta(product_id):\n",
    "    return [product_id] + sequences.get_meta(product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_product1 = val_samp['product1_id'].apply(get_id_and_meta)\n",
    "val_product2 = val_samp['product2_id'].apply(get_id_and_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [105831, 39]\n",
       "1        [117491, 34]\n",
       "2          [36325, 5]\n",
       "3        [104235, 20]\n",
       "4          [55705, 3]\n",
       "             ...     \n",
       "99995     [67609, 25]\n",
       "99996     [107264, 5]\n",
       "99997     [20998, 10]\n",
       "99998      [17168, 5]\n",
       "99999    [108845, 19]\n",
       "Name: product1_id, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_product1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-09 16:44:28,805 - Epoch: 0, Seq: 0/5,000, Loss: 0.4147, AUC-ROC: 0.5321, Lr: 0.025000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-ed2e3004c886>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Validation Check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mproduct1_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskipgram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_center_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_product1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mproduct2_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskipgram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_center_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_product2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mcos_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct1_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct2_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/recsys/src/ml/skipgram_with_meta_weighted.py\u001b[0m in \u001b[0;36mget_center_emb\u001b[0;34m(self, centers)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0memb_center\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0memb_center\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0memb_centers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_center\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/recsys/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.SparseAdam(skipgram.parameters(), lr=initial_lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(sequences_dload))\n",
    "    \n",
    "    running_loss = 0\n",
    "    for i, batches in enumerate(sequences_dload):\n",
    "\n",
    "        # logger.info('Batch shape: {}, {}, {}'.format(batches[0].shape, batches[1].shape, batches[2].shape))\n",
    "        centers = batches[0].to(device)\n",
    "        contexts = batches[1].to(device)\n",
    "        neg_contexts = batches[2].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = skipgram.forward(centers, contexts, neg_contexts)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        running_loss = running_loss * 0.9 + loss.item() * 0.1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            # Validation Check\n",
    "            with torch.no_grad():\n",
    "                product1_emb = skipgram.get_center_emb(torch.LongTensor(val_product1).to(device))\n",
    "                product2_emb = skipgram.get_center_emb(torch.LongTensor(val_product2).to(device))\n",
    "                cos_sim = F.cosine_similarity(product1_emb, product2_emb)\n",
    "                score = roc_auc_score(val_samp['edge'], cos_sim.detach().cpu().numpy())\n",
    "\n",
    "            logger.info(\"Epoch: {}, Seq: {:,}/{:,}, \" \\\n",
    "                        \"Loss: {:.4f}, AUC-ROC: {:.4f}, Lr: {:.6f}\".format(epoch, i, len(sequences_dload), running_loss,\n",
    "                                                                           score, optimizer.param_groups[0]['lr']))\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3912, -0.1188,  0.0619,  ...,  0.2390, -0.1749,  0.2658],\n",
       "        [-0.1681, -0.0960,  0.5144,  ...,  0.3660, -0.2210,  0.1719],\n",
       "        [ 0.0141,  0.0335, -0.2797,  ...,  0.5986, -0.2581,  0.2112],\n",
       "        ...,\n",
       "        [-0.1865,  0.3298, -0.3989,  ..., -0.0358,  0.1962,  0.2721],\n",
       "        [-0.2255,  0.5091, -0.3923,  ...,  0.6163, -0.0902,  0.0494],\n",
       "        [-0.4326,  0.4178, -0.1241,  ...,  0.2138,  0.5804,  0.0941]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product1_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-09 16:45:44,440 - SkipGram(\n",
      "  (center_embeddings): ModuleList(\n",
      "    (0): Embedding(133050, 8, sparse=True)\n",
      "    (1): Embedding(55, 8, sparse=True)\n",
      "  )\n",
      "  (context_embeddings): ModuleList(\n",
      "    (0): Embedding(133050, 8, sparse=True)\n",
      "    (1): Embedding(55, 8, sparse=True)\n",
      "  )\n",
      "  (emb_weights): Embedding(133050, 2, sparse=True)\n",
      "  (emb_weights_softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "logger.info('{}'.format(skipgram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = torch.LongTensor(val_product1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_centers = []\n",
    "for row_idx, center in enumerate(centers):\n",
    "    # logger.info('Row idx: {}, Center: {}'.format(row_idx, center))\n",
    "    emb_center = []\n",
    "    for col_idx, center_ in enumerate(center):\n",
    "        logger.info('Row idx: {}, col idx: {}, center_: {}'.format(row_idx, col_idx, center_))\n",
    "        emb_center.append(skipgram.center_embeddings[col_idx](center_))\n",
    "        \n",
    "    emb_centers.append(torch.mean(torch.stack(emb_center), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(emb_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(torch.stack(emb_center), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram.center_embeddings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product1_emb = skipgram.get_center_emb(torch.LongTensor(val_product1[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product1_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product2_emb = skipgram.get_center_emb(torch.LongTensor(val_product2[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product1_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cosine_similarity(product1_emb, product2_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product1_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(product1_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_product2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_samp = val_samp[(val_samp['product1_id'] > -1) & (val_samp['product2_id'] > -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product1_emb = model.get_center_emb(torch.LongTensor(product1_id))\n",
    "product2_emb = model.get_center_emb(torch.LongTensor(product2_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product1_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = F.cosine_similarity(product1_emb, product2_emb)\n",
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-0.2257,  0.2379, -0.2139,  0.2115,  0.2185, -0.2326,  0.2114, -0.2235])\n",
    "y = np.array([-0.2150, -0.1220,  0.0284,  0.2917,  0.1297, -0.2589, -0.1423, -0.2585])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.inner(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product1_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols = ['asin', 'price', 'category_lvl_2', 'category_lvl_3', 'category_lvl_4', 'brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = meta_cols.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.remove('asin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
