{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from src.utils.logger import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {'dim': 128,\n",
    "          'window': 5,\n",
    "          'min_count': 1,\n",
    "          'negative_samp': 5,\n",
    "          'epochs': 10,\n",
    "          'seed': 42}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.load('../data/books_sequences_sample.npy')\n",
    "sequences = sequences.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(sequences, window=5):\n",
    "    pairs = []\n",
    "    window = PARAMS['window']\n",
    "\n",
    "    for sequence in sequences:\n",
    "        for center_idx, node in enumerate(sequence):\n",
    "            for i in range(-window, window+1):\n",
    "                context_idx = center_idx + i\n",
    "                if context_idx > 0 and context_idx < len(sequence) and node != sequence[context_idx]:\n",
    "                    pairs.append((node, sequence[context_idx]))\n",
    "                    \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-27 12:04:13,047 - Len of pairs: 63,888\n"
     ]
    }
   ],
   "source": [
    "pairs = get_pairs(sequences, PARAMS['window'])\n",
    "logger.info('Len of pairs: {:,}'.format(len(pairs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negative_samples(sequences, power=0.75):\n",
    "    sample_table_size = 1e6\n",
    "    \n",
    "    # Flatten list\n",
    "    seq_flat = list(itertools.chain.from_iterable(sequences))\n",
    "    \n",
    "    # Get word frequency\n",
    "    word_freq = Counter(seq_flat)\n",
    "    \n",
    "    # Convert to array\n",
    "    word_freq = np.array(list(word_freq.items()), dtype=np.float64)\n",
    "    \n",
    "    # Adjust by power \n",
    "    word_freq[:, 1] = word_freq[:, 1] ** power\n",
    "    \n",
    "    # Get probabilities\n",
    "    word_freq_sum = word_freq[:, 1].sum()\n",
    "    word_freq[:, 1] = word_freq[:, 1] / word_freq_sum\n",
    "    \n",
    "    # Multiply probabilities by sample table size\n",
    "    word_freq[:, 1] = np.round(word_freq[:, 1] * sample_table_size)\n",
    "    \n",
    "    # Convert to int\n",
    "    word_freq = word_freq.astype(int).tolist()\n",
    "    \n",
    "    # Create sample table\n",
    "    sample_table = [[tup[0]] * tup[1] for tup in word_freq]\n",
    "    sample_table = list(itertools.chain.from_iterable(sample_table))\n",
    "    \n",
    "    return sample_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_table = get_negative_samples(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create skip-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0185, -0.0152, -0.0059,  0.0161, -0.0259, -0.0434, -0.0407,  0.0061,\n",
       "          0.0147, -0.0363],\n",
       "        [-0.0145,  0.0046, -0.0296, -0.0288, -0.0404,  0.0445,  0.0388, -0.0191,\n",
       "         -0.0246,  0.0424],\n",
       "        [-0.0435,  0.0442, -0.0046, -0.0249, -0.0112,  0.0221, -0.0455, -0.0396,\n",
       "          0.0460,  0.0369],\n",
       "        [-0.0415,  0.0203,  0.0182, -0.0139,  0.0436,  0.0256,  0.0357, -0.0126,\n",
       "          0.0469,  0.0110],\n",
       "        [-0.0050, -0.0477,  0.0295,  0.0130, -0.0281,  0.0094, -0.0473,  0.0017,\n",
       "          0.0454, -0.0103],\n",
       "        [ 0.0109, -0.0363,  0.0052, -0.0433,  0.0360,  0.0311,  0.0175, -0.0436,\n",
       "         -0.0159,  0.0490],\n",
       "        [ 0.0148,  0.0466,  0.0431,  0.0260, -0.0319, -0.0033, -0.0496, -0.0394,\n",
       "         -0.0053, -0.0259],\n",
       "        [ 0.0230, -0.0355, -0.0117, -0.0018,  0.0344, -0.0466,  0.0123, -0.0269,\n",
       "         -0.0371,  0.0148],\n",
       "        [-0.0123, -0.0059, -0.0144,  0.0006,  0.0430,  0.0382,  0.0173, -0.0130,\n",
       "         -0.0403,  0.0419],\n",
       "        [-0.0110,  0.0138,  0.0191,  0.0090,  0.0364, -0.0033, -0.0342, -0.0472,\n",
       "          0.0176, -0.0438]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_size=10\n",
    "emb_dim = 10\n",
    "u_embeddings = nn.Embedding(emb_size, emb_dim, sparse=True)\n",
    "v_embeddings = nn.Embedding(emb_size, emb_dim, sparse=True)\n",
    "\n",
    "initrange = 0.5/emb_size\n",
    "u_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "v_embeddings.weight.data.uniform_(-initrange, initrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0114,  0.0368, -0.0147,  0.0464,  0.0323,  0.0079, -0.0283, -0.0217,\n",
       "         -0.0451, -0.0026],\n",
       "        [-0.0292,  0.0343,  0.0427,  0.0311, -0.0375,  0.0035, -0.0429, -0.0261,\n",
       "         -0.0168, -0.0264],\n",
       "        [ 0.0489,  0.0181, -0.0218, -0.0067, -0.0157, -0.0236, -0.0153, -0.0209,\n",
       "          0.0285, -0.0310],\n",
       "        [-0.0244,  0.0109, -0.0453,  0.0263, -0.0247,  0.0163,  0.0304,  0.0101,\n",
       "         -0.0270, -0.0390],\n",
       "        [-0.0226,  0.0453, -0.0295, -0.0336, -0.0328, -0.0453, -0.0494, -0.0278,\n",
       "          0.0485,  0.0446],\n",
       "        [-0.0307,  0.0128, -0.0433, -0.0313,  0.0390, -0.0343,  0.0464,  0.0178,\n",
       "         -0.0122,  0.0433],\n",
       "        [ 0.0499,  0.0269, -0.0063, -0.0223, -0.0093, -0.0076,  0.0266, -0.0310,\n",
       "         -0.0078,  0.0239],\n",
       "        [-0.0006,  0.0291, -0.0166,  0.0286, -0.0494,  0.0380, -0.0094,  0.0287,\n",
       "          0.0103, -0.0302],\n",
       "        [-0.0485, -0.0298,  0.0009,  0.0145,  0.0481,  0.0285, -0.0376,  0.0436,\n",
       "         -0.0413,  0.0436],\n",
       "        [ 0.0468, -0.0414,  0.0043, -0.0223,  0.0489, -0.0020, -0.0387, -0.0236,\n",
       "          0.0274,  0.0134]], requires_grad=True)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt = [1, 2, 3]\n",
    "emb_u = u_embeddings(torch.LongTensor(inpt))\n",
    "emb_v = v_embeddings(torch.LongTensor(inpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0292,  0.0343,  0.0427,  0.0311, -0.0375,  0.0035, -0.0429, -0.0261,\n",
       "         -0.0168, -0.0264],\n",
       "        [ 0.0489,  0.0181, -0.0218, -0.0067, -0.0157, -0.0236, -0.0153, -0.0209,\n",
       "          0.0285, -0.0310],\n",
       "        [-0.0244,  0.0109, -0.0453,  0.0263, -0.0247,  0.0163,  0.0304,  0.0101,\n",
       "         -0.0270, -0.0390]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0145,  0.0046, -0.0296, -0.0288, -0.0404,  0.0445,  0.0388, -0.0191,\n",
       "         -0.0246,  0.0424],\n",
       "        [-0.0435,  0.0442, -0.0046, -0.0249, -0.0112,  0.0221, -0.0455, -0.0396,\n",
       "          0.0460,  0.0369],\n",
       "        [-0.0415,  0.0203,  0.0182, -0.0139,  0.0436,  0.0256,  0.0357, -0.0126,\n",
       "          0.0469,  0.0110]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.2301e-04,  1.5763e-04, -1.2648e-03, -8.9402e-04,  1.5161e-03,\n",
       "          1.5764e-04, -1.6655e-03,  4.9921e-04,  4.1257e-04, -1.1215e-03],\n",
       "        [-2.1268e-03,  7.9833e-04,  9.9889e-05,  1.6749e-04,  1.7612e-04,\n",
       "         -5.2174e-04,  6.9428e-04,  8.2802e-04,  1.3102e-03, -1.1436e-03],\n",
       "        [ 1.0119e-03,  2.2096e-04, -8.2383e-04, -3.6643e-04, -1.0789e-03,\n",
       "          4.1874e-04,  1.0859e-03, -1.2789e-04, -1.2679e-03, -4.2762e-04]],\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = torch.mul(emb_u, emb_v).squeeze()\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0018,  0.0003, -0.0014], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = torch.sum(score, dim=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6940, -0.6930, -0.6938], grad_fn=<LogSigmoidBackward>)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.logsigmoid(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0018,  0.0036, -0.0016],\n",
       "        [-0.0024,  0.0003, -0.0025],\n",
       "        [ 0.0027, -0.0027, -0.0014]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(emb_u, emb_v.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0145, -0.0435, -0.0415],\n",
       "        [ 0.0046,  0.0442,  0.0203],\n",
       "        [-0.0296, -0.0046,  0.0182],\n",
       "        [-0.0288, -0.0249, -0.0139],\n",
       "        [-0.0404, -0.0112,  0.0436],\n",
       "        [ 0.0445,  0.0221,  0.0256],\n",
       "        [ 0.0388, -0.0455,  0.0357],\n",
       "        [-0.0191, -0.0396, -0.0126],\n",
       "        [-0.0246,  0.0460,  0.0469],\n",
       "        [ 0.0424,  0.0369,  0.0110]], grad_fn=<TBackward>)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_v.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0145, -0.0435, -0.0415],\n",
       "        [ 0.0046,  0.0442,  0.0203],\n",
       "        [-0.0296, -0.0046,  0.0182],\n",
       "        [-0.0288, -0.0249, -0.0139],\n",
       "        [-0.0404, -0.0112,  0.0436],\n",
       "        [ 0.0445,  0.0221,  0.0256],\n",
       "        [ 0.0388, -0.0455,  0.0357],\n",
       "        [-0.0191, -0.0396, -0.0126],\n",
       "        [-0.0246,  0.0460,  0.0469],\n",
       "        [ 0.0424,  0.0369,  0.0110]], grad_fn=<TBackward>)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.t(emb_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_inpt = [[4, 5, 6, 7], [4, 5, 6, 7], [4, 5, 6, 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_emb_v = v_embeddings(torch.LongTensor(neg_inpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 10])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_emb_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 1])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_u.unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 1])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_score = torch.bmm(neg_emb_v, emb_u.unsqueeze(2))\n",
    "neg_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.0798, -2.0740, -2.0850, -2.0770], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(F.logsigmoid(-1*neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0036,  0.0015, -0.0093], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_score = torch.sum(neg_score, dim=1)\n",
    "neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.0774, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(F.logsigmoid(-1*neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0070, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses.append(sum(score))\n",
    "losses.append(sum(neg_score))\n",
    "-1 * sum(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0070, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1 * (sum(score) + sum(neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
